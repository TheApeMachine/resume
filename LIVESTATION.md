## Livestation : Full Stack Developer

LONDON: SEP 2011 - MAR 2013

### Stack

| Ruby (on Rails)     | OpenCV            | IOT              |
|---------------------|-------------------|------------------|
| Monolithic          | Computer Vision   | Samsung Smart TV |
| Postgres            | Machine Learning  | Second Screen    |
| Custom Video Player | Tesseract         | Smartphone App   |

### Remarks

In this project I found out that I have a passion for video streaming
and computer vision as out of the box solutions to problems in this
domain.

Besides a relatively tradional Ruby on Rails monolith to create
"personal" pages for the news channels we hosted and for viewers to
sign up to so they had an account for subscriptions we also worked a
lot on things like applications for smart devices, such as the Samsung Smart TV
that was current at the time.

We also had an in house team of C++ developers for which I recruited one member
additionally as I had previously worked with them and knew their skillset would
match.
They were responsible for a custom multi-bitrate stream which we could switch
by using our custom video player.
Things were not as simple as they are now in this regard back then.

Finally I developed a highly experimental solution to a requirement that stated
the company would like to find a solution to have real-time context on a live
(news) video stream.
Using a combination of techniques and something I developed myself based on
the game Scrabble it worked well enough to be usable as both an "alerting"
tool on news topics as well as pull related content from the YouTube API based
on the events happening on screen.
